{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "See our docs for an explanation of what this code is doing!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from docent import Docent\n",
    "\n",
    "client = Docent(\n",
    "    api_key=os.getenv(\"DOCENT_API_KEY\"),  # is default and can be omitted\n",
    "\n",
    "    # Uncomment and adjust these if you're self-hosting\n",
    "    # server_url=\"http://localhost:8889\",\n",
    "    # web_url=\"http://localhost:3001\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "collection_id = client.create_collection(name=\"tau-bench example\", description=\"example tau-bench-airline log that comes with the Docent repo\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from docent.samples import get_tau_bench_airline_fpath\n",
    "import json\n",
    "with open(get_tau_bench_airline_fpath(), \"r\") as f:\n",
    "    tb_log = json.load(f)\n",
    "print(tb_log)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Any\n",
    "\n",
    "from docent.data_models import AgentRun, Transcript\n",
    "from docent.data_models.chat import ChatMessage, ToolCall, parse_chat_message\n",
    "\n",
    "def load_tau_bench_log(data: dict[str, Any]) -> AgentRun:\n",
    "    traj, info, reward, task_id = data[\"traj\"], data[\"info\"], data[\"reward\"], data[\"task_id\"]\n",
    "\n",
    "    messages: list[ChatMessage] = []\n",
    "    for msg in traj:\n",
    "        # Extract raw message data\n",
    "        role = msg.get(\"role\")\n",
    "        content = msg.get(\"content\", \"\")\n",
    "        raw_tool_calls = msg.get(\"tool_calls\")\n",
    "        tool_call_id = msg.get(\"tool_call_id\")\n",
    "\n",
    "        # Create a message data dictionary\n",
    "        message_data = {\n",
    "            \"role\": role,\n",
    "            \"content\": content,\n",
    "        }\n",
    "\n",
    "        # For tool messages, include the tool name\n",
    "        if role == \"tool\":\n",
    "            message_data[\"name\"] = msg.get(\"name\")\n",
    "            message_data[\"tool_call_id\"] = tool_call_id\n",
    "\n",
    "        # For assistant messages, include tool calls if present\n",
    "        if role == \"assistant\" and raw_tool_calls:\n",
    "            # Convert tool calls to the expected format\n",
    "            parsed_tool_calls: list[ToolCall] = []\n",
    "            for tc in raw_tool_calls:\n",
    "                tool_call = ToolCall(\n",
    "                    id=tc.get(\"id\"),\n",
    "                    function=tc.get(\"function\", {}).get(\"name\"),\n",
    "                    arguments=tc.get(\"function\", {}).get(\"arguments\", {}),\n",
    "                    type=\"function\",\n",
    "                    parse_error=None,\n",
    "                )\n",
    "                parsed_tool_calls.append(tool_call)\n",
    "\n",
    "            message_data[\"tool_calls\"] = parsed_tool_calls\n",
    "\n",
    "        # Parse the message into the appropriate type\n",
    "        chat_message = parse_chat_message(message_data)\n",
    "        messages.append(chat_message)\n",
    "\n",
    "    # Extract metadata from the sample\n",
    "    task_id = info[\"task\"][\"user_id\"]\n",
    "    scores = {\"reward\": round(reward, 3)}\n",
    "\n",
    "    # Build metadata\n",
    "    metadata = {\n",
    "        \"benchmark_id\": task_id,\n",
    "        \"task_id\": task_id,\n",
    "        \"model\": \"sonnet-35-new\",\n",
    "        \"scores\": scores,\n",
    "        \"additional_metadata\": info,\n",
    "        \"scoring_metadata\": info[\"reward_info\"],\n",
    "    }\n",
    "\n",
    "    # Create the transcript and wrap in AgentRun\n",
    "    transcript = Transcript(\n",
    "        messages=messages,\n",
    "        metadata=metadata,\n",
    "    )\n",
    "    agent_run = AgentRun(\n",
    "        transcripts=[transcript],\n",
    "        metadata=metadata,\n",
    "    )\n",
    "\n",
    "    return agent_run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "agent_runs = [load_tau_bench_log(tb_log)]\n",
    "print(agent_runs[0].to_text_new())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "client.add_agent_runs(collection_id, agent_runs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
